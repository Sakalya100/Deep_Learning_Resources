{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word Embedding Techniques using Embedding Layer in Keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GN044OxIz9ks"
      },
      "outputs": [],
      "source": [
        "### Tensorflow > 2.0\n",
        "from tensorflow.keras.preprocessing.text import one_hot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Sentences\n",
        "sent =['the glass of milk',\n",
        "       'the glass of juice',\n",
        "       'the cup of tea',\n",
        "       'I am a good boy',\n",
        "       'I am a good Developer',\n",
        "       'Understand the meaning of words',\n",
        "       'Your videos are good']"
      ],
      "metadata": {
        "id": "a4s0dms00Nmn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWacmmXo0kQ6",
        "outputId": "9f2a4755-fd99-4b85-c0ad-b944621499b5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the glass of milk',\n",
              " 'the glass of juice',\n",
              " 'the cup of tea',\n",
              " 'I am a good boy',\n",
              " 'I am a good Developer',\n",
              " 'Understand the meaning of words',\n",
              " 'Your videos are good']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting the vocabulary size\n",
        "voc_size = 10000"
      ],
      "metadata": {
        "id": "Xhwvmq0c0krN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# One Hot Representation"
      ],
      "metadata": {
        "id": "npVfTKRk0sF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_repr = [one_hot(words,voc_size) for words in sent]\n",
        "print(onehot_repr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysPC6CMc0yPs",
        "outputId": "d2a65b0b-c604-4f7f-8a29-060d7273f903"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7758, 3263, 7790, 8823], [7758, 3263, 7790, 6924], [7758, 849, 7790, 4928], [2302, 704, 5896, 7133, 3835], [2302, 704, 5896, 7133, 8706], [3235, 7758, 2122, 7790, 7299], [2062, 8262, 9986, 7133]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Embedding Representation"
      ],
      "metadata": {
        "id": "y29cTcY51ApB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences # to make the size of sequences same to create a good embedding representation\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "mt4NMq6-1HM5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "oznYxPuJ1eKz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_length = 8 # The length that each sentence must be.\n",
        "embedded_docs = pad_sequences(onehot_repr, padding='pre', maxlen= sent_length)\n",
        "# The pre parameter add 0's to the front of each sentence to match sent_length\n",
        "print(embedded_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tP6PwZ1p1g0Y",
        "outputId": "2c8352ee-c912-462a-ad47-c899df6ac34f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   0    0    0    0 7758 3263 7790 8823]\n",
            " [   0    0    0    0 7758 3263 7790 6924]\n",
            " [   0    0    0    0 7758  849 7790 4928]\n",
            " [   0    0    0 2302  704 5896 7133 3835]\n",
            " [   0    0    0 2302  704 5896 7133 8706]\n",
            " [   0    0    0 3235 7758 2122 7790 7299]\n",
            " [   0    0    0    0 2062 8262 9986 7133]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dim=10"
      ],
      "metadata": {
        "id": "s9alhUJk2Ari"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(voc_size,10,input_length=sent_length))\n",
        "model.compile('adam','mse')"
      ],
      "metadata": {
        "id": "IqtTKFJM2M50"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wj6wFHC2YxX",
        "outputId": "12f39013-4917-438e-f348-17c8d1f33961"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 8, 10)             100000    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 100,000\n",
            "Trainable params: 100,000\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.predict(embedded_docs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3LgKCPN2afb",
        "outputId": "a9167899-6b91-427c-db09-8984238ba278"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[-0.01142468 -0.03784895 -0.01040639 -0.04113906  0.00872464\n",
            "    0.04556211  0.02771118  0.01823404 -0.04269209 -0.02533933]\n",
            "  [-0.01142468 -0.03784895 -0.01040639 -0.04113906  0.00872464\n",
            "    0.04556211  0.02771118  0.01823404 -0.04269209 -0.02533933]\n",
            "  [-0.01142468 -0.03784895 -0.01040639 -0.04113906  0.00872464\n",
            "    0.04556211  0.02771118  0.01823404 -0.04269209 -0.02533933]\n",
            "  [-0.01142468 -0.03784895 -0.01040639 -0.04113906  0.00872464\n",
            "    0.04556211  0.02771118  0.01823404 -0.04269209 -0.02533933]\n",
            "  [ 0.00588556 -0.04343342  0.03794089  0.04360607 -0.02765521\n",
            "   -0.01562198  0.00503638 -0.01395023  0.0018226  -0.01884951]\n",
            "  [-0.00433926 -0.00630044 -0.04953232  0.03645525 -0.04925347\n",
            "    0.03590101  0.0451285  -0.03737964  0.0135938  -0.03584465]\n",
            "  [-0.02035377  0.01268368 -0.00372165  0.04197291  0.02426687\n",
            "    0.00840374 -0.00037336 -0.01623069 -0.00467249 -0.00770698]\n",
            "  [-0.01130787  0.03038811  0.02868981 -0.0348345  -0.01029314\n",
            "   -0.04884185  0.0249348  -0.01022989 -0.0456485   0.03889407]]\n",
            "\n",
            " [[-0.01142468 -0.03784895 -0.01040639 -0.04113906  0.00872464\n",
            "    0.04556211  0.02771118  0.01823404 -0.04269209 -0.02533933]\n",
            "  [-0.01142468 -0.03784895 -0.01040639 -0.04113906  0.00872464\n",
            "    0.04556211  0.02771118  0.01823404 -0.04269209 -0.02533933]\n",
            "  [-0.01142468 -0.03784895 -0.01040639 -0.04113906  0.00872464\n",
            "    0.04556211  0.02771118  0.01823404 -0.04269209 -0.02533933]\n",
            "  [-0.01142468 -0.03784895 -0.01040639 -0.04113906  0.00872464\n",
            "    0.04556211  0.02771118  0.01823404 -0.04269209 -0.02533933]\n",
            "  [ 0.00588556 -0.04343342  0.03794089  0.04360607 -0.02765521\n",
            "   -0.01562198  0.00503638 -0.01395023  0.0018226  -0.01884951]\n",
            "  [-0.00433926 -0.00630044 -0.04953232  0.03645525 -0.04925347\n",
            "    0.03590101  0.0451285  -0.03737964  0.0135938  -0.03584465]\n",
            "  [-0.02035377  0.01268368 -0.00372165  0.04197291  0.02426687\n",
            "    0.00840374 -0.00037336 -0.01623069 -0.00467249 -0.00770698]\n",
            "  [ 0.0113163  -0.02850598  0.00760444  0.04926194 -0.03298049\n",
            "    0.00496236 -0.02494621 -0.02769538  0.04253106 -0.02680446]]\n",
            "\n",
            " [[-0.01142468 -0.03784895 -0.01040639 -0.04113906  0.00872464\n",
            "    0.04556211  0.02771118  0.01823404 -0.04269209 -0.02533933]\n",
            "  [-0.01142468 -0.03784895 -0.01040639 -0.04113906  0.00872464\n",
            "    0.04556211  0.02771118  0.01823404 -0.04269209 -0.02533933]\n",
            "  [-0.01142468 -0.03784895 -0.01040639 -0.04113906  0.00872464\n",
            "    0.04556211  0.02771118  0.01823404 -0.04269209 -0.02533933]\n",
            "  [-0.01142468 -0.03784895 -0.01040639 -0.04113906  0.00872464\n",
            "    0.04556211  0.02771118  0.01823404 -0.04269209 -0.02533933]\n",
            "  [ 0.00588556 -0.04343342  0.03794089  0.04360607 -0.02765521\n",
            "   -0.01562198  0.00503638 -0.01395023  0.0018226  -0.01884951]\n",
            "  [ 0.00254593  0.02184143  0.04395868  0.01623989  0.02635043\n",
            "    0.02085477 -0.01764488  0.03895701  0.01831246  0.02520726]\n",
            "  [-0.02035377  0.01268368 -0.00372165  0.04197291  0.02426687\n",
            "    0.00840374 -0.00037336 -0.01623069 -0.00467249 -0.00770698]\n",
            "  [-0.0395482  -0.02591461 -0.03252374  0.04048307 -0.03544017\n",
            "    0.01976943  0.01768455 -0.01241002 -0.04517496 -0.00518665]]\n",
            "\n",
            " [[-0.01142468 -0.03784895 -0.01040639 -0.04113906  0.00872464\n",
            "    0.04556211  0.02771118  0.01823404 -0.04269209 -0.02533933]\n",
            "  [-0.01142468 -0.03784895 -0.01040639 -0.04113906  0.00872464\n",
            "    0.04556211  0.02771118  0.01823404 -0.04269209 -0.02533933]\n",
            "  [-0.01142468 -0.03784895 -0.01040639 -0.04113906  0.00872464\n",
            "    0.04556211  0.02771118  0.01823404 -0.04269209 -0.02533933]\n",
            "  [ 0.02614609 -0.04331517 -0.0408258   0.02355414  0.03143347\n",
            "   -0.00219582 -0.00897796  0.01347674  0.01367733 -0.00404162]\n",
            "  [ 0.03861595 -0.00976834 -0.02773031  0.00394674 -0.00600272\n",
            "    0.01529667 -0.04255307 -0.00382844 -0.00390041  0.02803364]\n",
            "  [-0.04587443  0.00811978 -0.02820039 -0.01230121  0.03401328\n",
            "    0.04621729 -0.03630751 -0.0269388  -0.04248413  0.01836621]\n",
            "  [ 0.0089693  -0.03988872 -0.01408052 -0.00754236 -0.01108017\n",
            "   -0.01220043  0.04104166  0.02798912  0.01960707 -0.00330884]\n",
            "  [ 0.01947724  0.01166618  0.01643919  0.02954936  0.0172996\n",
            "   -0.04016308 -0.03174559 -0.00463337  0.03348667 -0.02169427]]\n",
            "\n",
            " [[-0.01142468 -0.03784895 -0.01040639 -0.04113906  0.00872464\n",
            "    0.04556211  0.02771118  0.01823404 -0.04269209 -0.02533933]\n",
            "  [-0.01142468 -0.03784895 -0.01040639 -0.04113906  0.00872464\n",
            "    0.04556211  0.02771118  0.01823404 -0.04269209 -0.02533933]\n",
            "  [-0.01142468 -0.03784895 -0.01040639 -0.04113906  0.00872464\n",
            "    0.04556211  0.02771118  0.01823404 -0.04269209 -0.02533933]\n",
            "  [ 0.02614609 -0.04331517 -0.0408258   0.02355414  0.03143347\n",
            "   -0.00219582 -0.00897796  0.01347674  0.01367733 -0.00404162]\n",
            "  [ 0.03861595 -0.00976834 -0.02773031  0.00394674 -0.00600272\n",
            "    0.01529667 -0.04255307 -0.00382844 -0.00390041  0.02803364]\n",
            "  [-0.04587443  0.00811978 -0.02820039 -0.01230121  0.03401328\n",
            "    0.04621729 -0.03630751 -0.0269388  -0.04248413  0.01836621]\n",
            "  [ 0.0089693  -0.03988872 -0.01408052 -0.00754236 -0.01108017\n",
            "   -0.01220043  0.04104166  0.02798912  0.01960707 -0.00330884]\n",
            "  [ 0.00309046 -0.01698561 -0.04383739  0.01620449 -0.01027878\n",
            "    0.03618239  0.04276127  0.0265654   0.01648421  0.02685852]]\n",
            "\n",
            " [[-0.01142468 -0.03784895 -0.01040639 -0.04113906  0.00872464\n",
            "    0.04556211  0.02771118  0.01823404 -0.04269209 -0.02533933]\n",
            "  [-0.01142468 -0.03784895 -0.01040639 -0.04113906  0.00872464\n",
            "    0.04556211  0.02771118  0.01823404 -0.04269209 -0.02533933]\n",
            "  [-0.01142468 -0.03784895 -0.01040639 -0.04113906  0.00872464\n",
            "    0.04556211  0.02771118  0.01823404 -0.04269209 -0.02533933]\n",
            "  [-0.03183407  0.0391953   0.04742508 -0.03568534  0.01417326\n",
            "    0.04241667 -0.03002911  0.03895028  0.01968158  0.0076161 ]\n",
            "  [ 0.00588556 -0.04343342  0.03794089  0.04360607 -0.02765521\n",
            "   -0.01562198  0.00503638 -0.01395023  0.0018226  -0.01884951]\n",
            "  [ 0.02619377  0.00849706 -0.04233355 -0.01683952  0.01002561\n",
            "    0.01037814 -0.01042795  0.0035228  -0.02728558 -0.04606502]\n",
            "  [-0.02035377  0.01268368 -0.00372165  0.04197291  0.02426687\n",
            "    0.00840374 -0.00037336 -0.01623069 -0.00467249 -0.00770698]\n",
            "  [ 0.03157606  0.01674428 -0.03562621 -0.01498755  0.02938118\n",
            "   -0.02187067 -0.01559919  0.01319199 -0.02635142  0.01492322]]\n",
            "\n",
            " [[-0.01142468 -0.03784895 -0.01040639 -0.04113906  0.00872464\n",
            "    0.04556211  0.02771118  0.01823404 -0.04269209 -0.02533933]\n",
            "  [-0.01142468 -0.03784895 -0.01040639 -0.04113906  0.00872464\n",
            "    0.04556211  0.02771118  0.01823404 -0.04269209 -0.02533933]\n",
            "  [-0.01142468 -0.03784895 -0.01040639 -0.04113906  0.00872464\n",
            "    0.04556211  0.02771118  0.01823404 -0.04269209 -0.02533933]\n",
            "  [-0.01142468 -0.03784895 -0.01040639 -0.04113906  0.00872464\n",
            "    0.04556211  0.02771118  0.01823404 -0.04269209 -0.02533933]\n",
            "  [-0.04297657 -0.03563493  0.0078458   0.0425424   0.02082418\n",
            "    0.00663926  0.01208609 -0.04394744  0.00840006  0.02978425]\n",
            "  [ 0.03801537  0.03270706  0.00619259 -0.04176693  0.03069108\n",
            "    0.00247953  0.02086121  0.0374837  -0.04617444  0.00646709]\n",
            "  [ 0.02163234  0.00039126  0.02601926 -0.01486933  0.04439541\n",
            "   -0.02838372  0.04372336 -0.01900525 -0.00248517 -0.00140513]\n",
            "  [ 0.0089693  -0.03988872 -0.01408052 -0.00754236 -0.01108017\n",
            "   -0.01220043  0.04104166  0.02798912  0.01960707 -0.00330884]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x59zox8N2fze",
        "outputId": "71e150a4-c353-4613-9694-f6656a3c75e1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0, 7758, 3263, 7790, 8823], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(embedded_docs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQiKpGnR2lKi",
        "outputId": "67c45acf-1b74-4521-a9e3-dfaa3d9cb5b0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None,).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.01142468, -0.03784895, -0.01040639, -0.04113906,  0.00872464,\n",
              "         0.04556211,  0.02771118,  0.01823404, -0.04269209, -0.02533933],\n",
              "       [-0.01142468, -0.03784895, -0.01040639, -0.04113906,  0.00872464,\n",
              "         0.04556211,  0.02771118,  0.01823404, -0.04269209, -0.02533933],\n",
              "       [-0.01142468, -0.03784895, -0.01040639, -0.04113906,  0.00872464,\n",
              "         0.04556211,  0.02771118,  0.01823404, -0.04269209, -0.02533933],\n",
              "       [-0.01142468, -0.03784895, -0.01040639, -0.04113906,  0.00872464,\n",
              "         0.04556211,  0.02771118,  0.01823404, -0.04269209, -0.02533933],\n",
              "       [ 0.00588556, -0.04343342,  0.03794089,  0.04360607, -0.02765521,\n",
              "        -0.01562198,  0.00503638, -0.01395023,  0.0018226 , -0.01884951],\n",
              "       [-0.00433926, -0.00630044, -0.04953232,  0.03645525, -0.04925347,\n",
              "         0.03590101,  0.0451285 , -0.03737964,  0.0135938 , -0.03584465],\n",
              "       [-0.02035377,  0.01268368, -0.00372165,  0.04197291,  0.02426687,\n",
              "         0.00840374, -0.00037336, -0.01623069, -0.00467249, -0.00770698],\n",
              "       [-0.01130787,  0.03038811,  0.02868981, -0.0348345 , -0.01029314,\n",
              "        -0.04884185,  0.0249348 , -0.01022989, -0.0456485 ,  0.03889407]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ref Link : https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/"
      ],
      "metadata": {
        "id": "EXAeq-zM2oQ7"
      }
    }
  ]
}